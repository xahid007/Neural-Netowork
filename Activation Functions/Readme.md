# Activation Functions
In this section we will see some common activation functions and their python implemention


### Sigmoid Function
$\sigma(x) = \frac{1}{1 + e^-x}$

### tanh
$tanh(x) = \frac{e^x - e^-x}{e^x + e^-x}$


### ReLU (Rectified Linear unit)
$rel = \left\{\begin{matrix}
1 & if x \text{ }}< 0&\\ 
0 & if x\leq 0 & 
\end{matrix}\right.$


